{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.9.19 torch-2.0.1+cu117 CPU (12th Gen Intel Core(TM) i9-12900H)\n",
      "YOLOv10n summary (fused): 285 layers, 2,695,196 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'new_v10_480.pt' with input shape (1, 3, 480, 480) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as 'new_v10_480.onnx' (8.8 MB)\n",
      "\n",
      "Export complete (3.0s)\n",
      "Results saved to \u001b[1m/home/kenna/dvd\u001b[0m\n",
      "Predict:         yolo predict task=detect model=new_v10_480.onnx imgsz=480  \n",
      "Validate:        yolo val task=detect model=new_v10_480.onnx imgsz=480 data=data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "Ultralytics YOLOv8.2.58 ðŸš€ Python-3.9.19 torch-2.0.1+cu117 CPU (12th Gen Intel Core(TM) i9-12900H)\n",
      "YOLOv10n summary (fused): 285 layers, 2,695,196 parameters, 0 gradients, 8.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'new_v10_480.pt' with input shape (1, 3, 480, 480) BCHW and output shape(s) (1, 300, 6) (5.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.2.0-15519-5c0f38f83f6-releases/2024/2...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success âœ… 7.8s, saved as 'new_v10_480_openvino_model/' (9.0 MB)\n",
      "\n",
      "Export complete (9.7s)\n",
      "Results saved to \u001b[1m/home/kenna/dvd\u001b[0m\n",
      "Predict:         yolo predict task=detect model=new_v10_480_openvino_model imgsz=480  \n",
      "Validate:        yolo val task=detect model=new_v10_480_openvino_model imgsz=480 data=data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'new_v10_480_openvino_model'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model10 = YOLO('new_v10_480.pt')\n",
    "model10.export(format=\"onnx\", imgsz = 480)\n",
    "model10.export(format=\"openvino\", imgsz=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=yolov5/data/coco128.yaml, weights=['/home/kenna/dvd/pretrained_weights/yolov5m6.pt'], imgsz=[640, 640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, per_tensor=False, dynamic=False, simplify=False, opset=17, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "YOLOv5 ðŸš€ v7.0-334-g100a423b Python-3.9.19 torch-2.0.1+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m6 summary: 378 layers, 35704908 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /home/kenna/dvd/pretrained_weights/yolov5m6.pt with output shape (1, 25500, 85) (69.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0...\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 3.1s, saved as /home/kenna/dvd/pretrained_weights/yolov5m6.onnx (136.7 MB)\n",
      "\n",
      "Export complete (5.7s)\n",
      "Results saved to \u001b[1m/home/kenna/dvd/pretrained_weights\u001b[0m\n",
      "Detect:          python detect.py --weights /home/kenna/dvd/pretrained_weights/yolov5m6.onnx \n",
      "Validate:        python val.py --weights /home/kenna/dvd/pretrained_weights/yolov5m6.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', '/home/kenna/dvd/pretrained_weights/yolov5m6.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!python /home/kenna/dvd/yolov5/export.py --weights /home/kenna/dvd/pretrained_weights/yolov5m6.pt --include onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "model = ov.convert_model('pretrained_weights/yolov5m6.onnx')\n",
    "ov.save_model(model, 'pretrained_weights/yolov5m6.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.73 ðŸš€ Python-3.9.19 torch-2.0.1+cu117 CPU (12th Gen Intel Core(TM) i9-12900H)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=pretrained_weights/yolov10n.pt, data=drive_data.yaml, epochs=300, time=None, patience=30, batch=30, imgsz=480, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=retrained_v10n, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/retrained_v10n\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    862108  ultralytics.nn.modules.head.v10Detect        [2, [64, 128, 256]]           \n",
      "YOLOv10n summary: 385 layers, 2,707,820 parameters, 2,707,804 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/kenna/dvd/drive_data/train/labels... 10213 images, 738 bac\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/kenna/dvd/drive_data/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/kenna/dvd/drive_data/val/labels... 1123 images, 21 backgroun\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/kenna/dvd/drive_data/val/labels.cache\n",
      "Plotting labels to runs/detect/retrained_v10n/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.00046875), 107 bias(decay=0.0)\n",
      "Image sizes 480 train, 480 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/retrained_v10n\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/300         0G       5.62      23.71      2.167         42        480:  ^C\n",
      "      1/300         0G       5.62      23.71      2.167         42        480:  \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/bin/yolo\", line 8, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/ultralytics/cfg/__init__.py\", line 834, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/ultralytics/engine/model.py\", line 811, in train\n",
      "    self.trainer.train()\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/ultralytics/engine/trainer.py\", line 206, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/ultralytics/engine/trainer.py\", line 383, in _do_train\n",
      "    self.loss, self.loss_items = self.model(batch)\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/ultralytics/nn/tasks.py\", line 101, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/ultralytics/nn/tasks.py\", line 283, in loss\n",
      "    return self.criterion(preds, batch)\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/ultralytics/utils/loss.py\", line 739, in __call__\n",
      "    loss_one2many = self.one2many(one2many, batch)\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/ultralytics/utils/loss.py\", line 230, in __call__\n",
      "    pred_bboxes = self.bbox_decode(anchor_points, pred_distri)  # xyxy, (b, h*w, 4)\n",
      "  File \"/home/kenna/anaconda3/envs/tf-gpu-3.9/lib/python3.9/site-packages/ultralytics/utils/loss.py\", line 202, in bbox_decode\n",
      "    pred_dist = pred_dist.view(b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Train Yolov10n\n",
    "!yolo task=detect mode=train epochs=300 patience=30 batch=30 plots=True model=pretrained_weights/yolov10n.pt data=drive_data.yaml imgsz=480 name=retrained_v10n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
